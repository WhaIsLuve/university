### 1. Основные понятия нейронных сетей (HC): преимущества HC
**Ответ:**
Нейронные сети обладают следующими ключевыми преимуществами:
- **Адаптивность:** Способность обучаться на данных без явного программирования
- **Устойчивость к шуму:** Могут работать с неполными или зашумленными данными
- **Параллельная обработка:** Одновременное выполнение множества операций
- **Нелинейность:** Возможность моделировать сложные зависимости с помощью функций активации:
  $$\sigma(x) = \frac{1}{1 + e^{-x}}$$
- **Универсальность:** Применимы для широкого круга задач (классификация, регрессия и др.)

### 2. Основные понятия нейронных сетей (HC): модели нейронов
**Ответ:**
Модель искусственного нейрона включает:
1. Входные сигналы: $x_1, x_2, ..., x_n$
2. Весовые коэффициенты: $w_1, w_2, ..., w_n$
3. Сумматор:
   $$z = \sum_{i=1}^n w_i x_i + b$$
   где $b$ - смещение
4. Функцию активации $f(z)$, например:
   - ReLU: $f(z) = max(0, z)$
   - Сигмоида: $f(z) = \sigma(z)$

### 3. Основные понятия нейронных сетей (HC): направленные графы
**Ответ:**
Нейросети представляются как ориентированные графы, где:
- **Вершины:** Нейроны, объединенные в слои
- **Ребра:** Направленные связи с весами $w_{ij}$
- **Типы архитектур:**
  - Прямые (feedforward) - без циклов
  - Рекуррентные - с циклами для временных зависимостей

### 4. Основные понятия нейронных сетей (HC): обратная связь
**Ответ:**
Обратная связь означает передачу выходного сигнала обратно на вход. Пример:
- В рекуррентных сетях (RNN):
  $$h_t = f(W_{hh} h_{t-1} + W_{xh} x_t)$$
  где $h_t$ - состояние на шаге $t$
- Применяется для обработки последовательностей

### 5. Основные понятия нейронных сетей (HC): архитектура HC
**Ответ:**
Основные архитектуры:
1. Однослойные (перцептрон)
2. Многослойные (MLP):
   $$y = f_2\left(\sum w_{ij}^{(2)} f_1\left(\sum w_{ij}^{(1)} x_i\right)\right)$$
3. Специализированные:
   - CNN для изображений
   - RNN для последовательностей

### 6. Основные понятия нейронных сетей (HC): представление знаний
**Ответ:**
Знания в НС представлены:
- Весами связей $w_{ij}$
- Активациями нейронов
- Распределенно в сети

### 7. Нейронные сети и искусственный интеллект
**Ответ:**
НС - ключевой инструмент ИИ для:
- Машинного обучения
- Глубокого обучения
- Решения сложных задач (NLP, CV)

### 8. Основные подходы к обучению: коррекция ошибок
**Ответ:**
Методы минимизации ошибки:
- Градиентный спуск:
  $$w_{ij} \leftarrow w_{ij} - \eta \frac{\partial E}{\partial w_{ij}}$$
- Правило Уидроу-Хоффа:
  $$\Delta w_i = \eta (y_{target} - y_{output}) x_i$$

### 9. Основные подходы к обучению: обучение на основе памяти
**Ответ:**
Пример - метод k-ближайших соседей (k-NN):
$$\hat{y} = \text{majority}(y_1, ..., y_k)$$
Недостаток: высокие вычислительные затраты

### 10. Основные подходы к обучению: обучение Хебба
**Ответ:**
Правило Хебба:
$$\Delta w_{ij} = \eta x_i y_j$$
Где:
- $x_i$ - вход
- $y_j$ - выход
Применяется для ассоциативной памяти
### 11. Основные подходы к обучению: конкурентное обучение
**Ответ:**
Конкурентное обучение - это метод без учителя, где нейроны соревнуются за право активироваться:
- Принцип "победитель получает все" (Winner-Takes-All)
- Формула обновления весов для нейрона-победителя:
  $$w_{ij} = w_{ij} + \eta(x_i - w_{ij})$$
- Применяется в Kohonen Self-Organizing Maps (SOM)

### 12. Основные подходы к обучению: обучение Больцмана
**Ответ:**
Машина Больцмана - стохастическая нейронная сеть:
- Вероятность активации нейрона:
  $$P(x_i=1) = \frac{1}{1+e^{-\Delta E_i/T}}$$
  где $\Delta E_i$ - изменение энергии, $T$ - температура
- Использует алгоритм имитации отжига

### 13. Основные подходы к обучению: обучение с учителем
**Ответ:**
Характеристики обучения с учителем:
- Требуется размеченный набор данных (X, y)
- Цель - минимизация ошибки между предсказанием и истинным значением:
  $$E = \frac{1}{2}\sum(y_{true} - y_{pred})^2$$
- Примеры: обратное распространение, SVM

### 14. Основные подходы к обучению: обучение без учителя
**Ответ:**
Особенности обучения без учителя:
- Работает с неразмеченными данными (только X)
- Цели:
  - Кластеризация
  - Снижение размерности
  - Поиск закономерностей
- Примеры: k-means, PCA, автоэнкодеры

### 15. Основные подходы к обучению: задачи обучения
**Ответ:**
Основные задачи обучения НС:
1. Классификация
2. Регрессия
3. Кластеризация
4. Генерация данных
5. Уменьшение размерности
6. Аппроксимация функций

### 16. Однослойный персептрон: адаптивная фильтрация
**Ответ:**
Адаптивные фильтры на основе персептрона:
- Обновление весов по правилу LMS:
  $$\Delta w_i = \eta e(n)x_i(n)$$
  где $e(n)$ - ошибка на шаге $n$
- Применение: шумоподавление, предсказание сигналов

### 17. Однослойный персептрон: методы оптимизации
**Ответ:**
Основные методы оптимизации:
1. Стохастический градиентный спуск (SGD)
2. Momentum:
   $$v_t = \gamma v_{t-1} + \eta\nabla J(\theta)$$
3. AdaGrad
4. RMSprop

### 18. Однослойный персептрон: фильтр на основе метода наименьших квадратов
**Ответ:**
Фильтр наименьших квадратов:
- Минимизирует целевую функцию:
  $$J(w) = \frac{1}{2}\sum_{i=1}^N(y_i - w^Tx_i)^2$$
- Решение в закрытой форме:
  $$w = (X^TX)^{-1}X^Ty$$

### 19. Однослойный персептрон: алгоритм минимизации среднеквадратической ошибки
**Ответ:**
Алгоритм минимизации MSE:
1. Инициализация весов
2. Вычисление ошибки:
   $$E = \frac{1}{2N}\sum(y - \hat{y})^2$$
3. Обновление весов:
   $$w \leftarrow w - \eta\frac{\partial E}{\partial w}$$
4. Повтор до сходимости

### 20. Однослойный персептрон: персептрон Розенблатта
**Ответ:**
Перцептрон Розенблатта - первая модель ИНС:
- Архитектура: входной слой + один выходной нейрон
- Функция активации - ступенчатая:
  $$f(z) = \begin{cases} 
  1 & \text{если } z \geq 0 \\
  0 & \text{иначе}
  \end{cases}$$
- Ограничение: решает только линейно разделимые задачи
### 21. Многослойный персептрон: алгоритм обратного распространения
**Ответ:**
Алгоритм обратного распространения состоит из:
1. **Прямого прохода**:
   - Вычисление выхода каждого слоя через взвешенную сумму входов и функцию активации
2. **Обратного прохода**:
   - Расчет ошибки на выходном слое
   - Послойное распространение ошибки назад
   - Корректировка весов с помощью градиентного спуска

### 22. Многослойный персептрон: обратное распространение ошибки и дифференцирование
**Ответ:**
Процесс использует:
- **Цепное правило** для расчета производных
- Для каждого веса вычисляется:
  *Производная ошибки по весу = (Ошибка следующего слоя) × (Производная функции активации) × (Значение предыдущего слоя)*

### 23. Многослойный персептрон: обучение методом обратного распространения
**Ответ:**
Этапы обучения:
1. Инициализация случайных весов
2. Для каждой эпохи:
   - Прямой проход (вычисление предсказания)
   - Сравнение с целевым значением (расчет ошибки)
   - Обратный проход (корректировка весов)
   - Повтор до достижения сходимости

### 24. Многослойный персептрон: сети свертки
**Ответ:**
CNN (Сверточные сети) содержат:
- **Сверточные слои**:
  - Применение фильтров к локальным областям
  - Выделение локальных признаков
- **Слои подвыборки (pooling)**:
  - Уменьшение размерности (max/average)
- **Полносвязные слои** для классификации

### 25. RBF-сети: сети регуляризации
**Ответ:**
Особенности:
- Используют радиальные базисные функции (обычно Гауссовы)
- Добавляют штраф за большие веса (L2-регуляризация)
- Хорошо работают на небольших наборах данных

### 26. Обобщенные RBF-сети
**Ответ:**
Усовершенствования:
- Разные типы ядерных функций
- Адаптивный подбор центров и параметров
- Комбинации с другими архитектурами

### 27. RBF-сети: стратегии обучения
**Ответ:**
Основные подходы:
1. Фиксированные центры (случайный выбор)
2. Кластеризация для определения центров
3. Градиентный спуск для всех параметров
4. Гибридные методы (двухэтапное обучение)

### 28. SVM для распознавания образов
**Ответ:**
Принципы работы:
- Поиск оптимальной разделяющей гиперплоскости
- Максимизация зазора между классами
- Использование ядер для нелинейных случаев

### 29. SVM для нелинейной регрессии
**Ответ:**
SVR особенности:
- Использует ε-нечувствительную функцию потерь
- Допускает отклонения в пределах ε-трубки
- Сохраняет преимущества SVM (ядра, разреженность)

### 30. Ассоциативные машины: методы усреднения
**Ответ:**
Основные методы:
1. **Bagging**:
   - Множество моделей на подвыборках
   - Усреднение результатов
2. **Случайный лес**:
   - Комбинация решающих деревьев
   - Дополнительная случайность в признаках
### 31. Ассоциативные машины: методы усиления
**Ответ:**
Методы усиления (boosting) последовательно улучшают модель:
1. **AdaBoost**:
   - Веса ошибочных примеров увеличиваются:
     $$w_i^{(t+1)} = w_i^{(t)} \cdot e^{\alpha_t \cdot \mathbb{I}(y_i \neq h_t(x_i))}$$
   - Финальное решение:
     $$H(x) = \text{sign}\left(\sum_{t=1}^T \alpha_t h_t(x)\right)$$
2. **Gradient Boosting**:
   - Оптимизирует функцию потерь через градиентный спуск

### 32. Ассоциативные машины: методы иерархического смешения экспертов
**Ответ:**
Архитектура Mixture of Experts (MoE):
1. **Гейтинг-сеть**:
   $$g(x) = \text{softmax}(W_g x)$$
2. **Эксперты**:
   $$E_i(x) = f(W_i x)$$
3. **Финальный выход**:
   $$y = \sum_{i=1}^k g_i(x) \cdot E_i(x)$$
Применение: сложные многомодальные данные

### 33. Структура анализа главных компонентов
**Ответ:**
PCA включает:
1. **Стандартизацию данных**:
   $$X_{std} = \frac{X - \mu}{\sigma}$$
2. **Собственные векторы ковариационной матрицы**:
   $$\Sigma = \frac{1}{n} X^T X$$
3. **Проецирование**:
   $$Z = X W$$
   где $W$ - матрица собственных векторов

### 34. PCA: основные представления данных
**Ответ:**
Ключевые аспекты:
- **Объясненная дисперсия**:
  $$\lambda_i / \sum_{j=1}^p \lambda_j$$
- **Геометрическая интерпретация**:
  $$\|X - XWW^T\|^2 \rightarrow \min$$
- **Оптимальность**: PCA дает наилучшую линейную аппроксимацию

### 35. PCA: сокращение размерности
**Ответ:**
Процесс уменьшения размерности:
1. Выбор $k$ главных компонент
2. Проецирование:
   $$Z_k = X W_k$$
3. Восстановление:
   $$\tilde{X} = Z_k W_k^T$$
Критерий выбора $k$: 95% объясненной дисперсии

### 36. PCA на основе фильтра Хебба
**Ответ:**
Нейросетевой вариант PCA:
1. **Однослойная сеть** с линейными нейронами
2. **Правило Ойи** (модификация Хебба):
   $$\Delta w_{ij} = \eta (y_i x_j - y_i^2 w_{ij})$$
3. **Результат**: веса сходятся к собственным векторам

### 37. Карты самоорганизации: процессы конкуренции
**Ответ:**
Этап конкуренции в SOM:
1. **Нахождение BMU** (Best Matching Unit):
   $$\|x - w_c\| = \min_i \|x - w_i\|$$
2. **Метрика расстояния**:
   $$d(x,w_i) = \sqrt{\sum_{j=1}^d (x_j - w_{ij})^2}$$

### 38. Карты самоорганизации: процессы кооперации
**Ответ:**
Кооперация между нейронами:
1. **Окрестностная функция**:
   $$h_{ci}(t) = \exp\left(-\frac{\|r_c - r_i\|^2}{2\sigma^2(t)}\right)$$
2. **Радиус окрестности** уменьшается со временем:
   $$\sigma(t) = \sigma_0 \exp(-t/\lambda)$$

### 39. Карты самоорганизации: процессы адаптации
**Ответ:**
Обновление весов:
$$\Delta w_i = \eta(t) \cdot h_{ci}(t) \cdot (x - w_i)$$
где:
- $\eta(t)$ - скорость обучения:
  $$\eta(t) = \eta_0 \exp(-t/\lambda)$$
- $h_{ci}(t)$ - функция окрестности

### 40. Карты самоорганизации: этапы адаптации
**Ответ:**
Два основных этапа:
1. **Упорядочивание** (1000+ итераций):
   - Большой радиус окрестности
   - Высокая скорость обучения
2. **Точная настройка**:
   - Малый радиус
   - Низкая скорость обучения
### 41. Стохастические машины: машина Больцмана
**Ответ:**
Машина Больцмана - это стохастическая нейронная сеть с:
1. **Энергетической функцией**:
   $$E = -\sum_{i<j} w_{ij} s_i s_j + \sum_i \theta_i s_i$$
2. **Вероятностью активации**:
   $$P(s_i=1) = \frac{1}{1+e^{-\Delta E_i/T}}$$
3. **Обучение** через алгоритм контрастивной дивергенции

### 42. Стохастические машины: машина Гельмгольца
**Ответ:**
Особенности машины Гельмгольца:
1. **Двунаправленная архитектура**:
   - Генеративный путь (восстановление данных)
   - Распознающий путь (извлечение признаков)
2. **Функционал свободной энергии**:
   $$F = -\log \sum_h e^{-E(v,h)}$$

### 43. Нейродинамическое программирование и обучение с подкреплением
**Ответ:**
Связь подходов:
1. **Функция ценности**:
   $$V^\pi(s) = \mathbb{E}_\pi\left[\sum_{k=0}^\infty \gamma^k r_{t+k} | s_t = s\right]$$
2. **Уравнение Беллмана**:
   $$V^\pi(s) = \sum_a \pi(a|s) \sum_{s'} P(s'|s,a)[r(s,a) + \gamma V^\pi(s')]$$
3. **Аппроксимация нейросетями** (DQN, Policy Gradients)

### 44. Нелинейные динамические системы: многослойные сети прямого распространения
**Ответ:**
Свойства:
1. **Универсальная аппроксимация**:
   $$\forall f \in C(X), \exists NN: \|f(x) - NN(x)\| < \epsilon$$
2. **Динамика обучения**:
   $$\frac{dw}{dt} = -\eta \nabla_w J(w)$$
3. **Условия устойчивости**:
   $$\text{Re}(\lambda(\nabla^2 J)) > 0$$

### 45. Нелинейные динамические системы: рекуррентные сети
**Ответ:**
Основные модели:
1. **Дискретное время**:
   $$h_t = \sigma(W_{hh}h_{t-1} + W_{xh}x_t + b)$$
2. **Непрерывное время** (нейронные ОДУ):
   $$\frac{dh}{dt} = f(h(t), x(t), \theta)$$
3. **Устойчивость** через спектральный радиус $\rho(W_{hh}) < 1$
